{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package to implement Decision Tree Model\n",
    "import pandas as pd             # Pandas\n",
    "import streamlit as st          # Streamlit\n",
    "import matplotlib.pyplot as plt # Matplotlib\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Package for data partitioning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Package to calculate f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "bike_data_train = pd.read_csv('bike.csv')\n",
    "output = bike_data_train['cnt']\n",
    "features = bike_data_train[['season','mnth','holiday','weekday','workingday','weathersit','temp','atemp','hum','windspeed']]\n",
    "X = features\n",
    "y = output\n",
    "cat_var = X['weathersit']\n",
    "X_encoded = pd.get_dummies(X, columns=cat_var)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_encoded, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# DT REGRESSOR CONFIGURATION    \n",
    "bk_r = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "hyper_params = {\n",
    "    'max_depth': list(range(30,50)),\n",
    "    'min_samples_split': list(range(3,12)),\n",
    "    'min_samples_leaf': list(range(3,15))\n",
    "}\n",
    "\n",
    "fold_r  = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "model_cv = GridSearchCV(estimator = bk_r,\n",
    "                        param_grid = hyper_params,\n",
    "                        scoring= 'r2',\n",
    "                        cv=fold_r,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "model_cv.fit(train_X, train_y)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "#cv_results\n",
    "\n",
    "print('Initial score: ', model_cv.best_score_)\n",
    "print('Initial parameters: ', model_cv.best_params_)\n",
    "\n",
    "bestClassTree = model_cv.best_estimator_\n",
    "print(bestClassTree)\n",
    "y_pred_train = model_cv.predict(train_X)\n",
    "y_pred = model_cv.predict(test_X)\n",
    "\n",
    "\n",
    "# TRAINED TREE VISUALIZATION\n",
    "bestClassTree1 = model_cv.best_estimator_\n",
    "print(bestClassTree1)\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "a = tree.plot_tree(decision_tree = bestClassTree1,\n",
    "                    feature_names = train_X.columns,\n",
    "                    class_names = ['0','1','2','3'],\n",
    "                    filled = True)\n",
    "a;\n",
    "    # FEATURE IMPORTANCE PLOT\n",
    "    importance = bestClassTree.feature_importances_\n",
    "    feature_imp = pd.DataFrame(list(zip(train_X.columns, importance)),\n",
    "                columns = ['Feature', 'Importance'])\n",
    "\n",
    "    feature_imp = feature_imp.sort_values('Importance', ascending = False).reset_index(drop = True)\n",
    "\n",
    "    feature_imp\n",
    "\n",
    "    feature_imp_nonzero = feature_imp[feature_imp['Importance'] != 0.0]\n",
    "    plt.figure(figsize=(10, 5), dpi = 100)\n",
    "    plt.barh(feature_imp_nonzero['Feature'], feature_imp_nonzero['Importance'], color = ['orange', 'blue'])\n",
    "\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Input Feature\")\n",
    "    plt.title(\"Feature Importance\");"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
